{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zr8akaTQxba",
        "outputId": "6e79d731-19da-485a-9acc-4e2548bae191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 39s 40ms/step - loss: 0.2640 - accuracy: 0.9251 - val_loss: 0.1038 - val_accuracy: 0.9717\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0914 - accuracy: 0.9738 - val_loss: 0.0733 - val_accuracy: 0.9773\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0681 - accuracy: 0.9802 - val_loss: 0.0621 - val_accuracy: 0.9797\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.0568 - accuracy: 0.9834 - val_loss: 0.0604 - val_accuracy: 0.9792\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0503 - accuracy: 0.9854 - val_loss: 0.0546 - val_accuracy: 0.9822\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0546 - accuracy: 0.9822\n",
            "Test accuracy: 0.982200026512146\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# Convert labels to categorical\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
        "\n",
        "# Build a simple CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import TensorFlow Library:\n",
        "\n"
      ],
      "metadata": {
        "id": "Iu8DxCWQt6nK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-tvkJqNt7YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iMfa5HZit7tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "rf4gSvymt72B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line imports the TensorFlow library, which is an open-source machine learning framework.\n",
        "\n",
        "Import MNIST Dataset:"
      ],
      "metadata": {
        "id": "BlqThSFRt7-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n"
      ],
      "metadata": {
        "id": "mZd51E9st8GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line imports the MNIST dataset, which is a well-known dataset of handwritten digits used for training and evaluating machine learning models.\n",
        "\n",
        "Load the MNIST Dataset:"
      ],
      "metadata": {
        "id": "hS3onuWst8PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "CrX1wmAIt8V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet loads the MNIST dataset into four variables: train_images, train_labels, test_images, and test_labels. The dataset consists of training images and labels, as well as testing images and labels.\n",
        "\n",
        "Preprocess the Data:"
      ],
      "metadata": {
        "id": "oqqkE9FCt8dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n"
      ],
      "metadata": {
        "id": "sRgUSRkUt8kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These lines reshape and normalize the image data. The images are reshaped to have dimensions (28, 28, 1) and are then normalized by dividing the pixel values by 255 to scale them to the range [0, 1].\n",
        "\n",
        "Convert Labels to Categorical:"
      ],
      "metadata": {
        "id": "vFW1PZQet8s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)\n"
      ],
      "metadata": {
        "id": "pDeLz0vpt80I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These lines convert the integer labels into categorical one-hot encoded vectors. This is necessary for training a neural network classification model.\n",
        "\n",
        "Build a Convolutional Neural Network (CNN) Model:"
      ],
      "metadata": {
        "id": "BWFcdaKKt87p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "iSs-dKd8t9Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a simple CNN model using the Keras Sequential API. It consists of a convolutional layer with 32 filters, followed by max-pooling, flattening, and a dense output layer with 10 units and softmax activation.\n",
        "\n",
        "Compile the Model:"
      ],
      "metadata": {
        "id": "Xr0wdpLwt9J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "U2yujJy-t9Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is compiled with the Adam optimizer, categorical cross-entropy loss (appropriate for multi-class classification), and accuracy as the evaluation metric.\n",
        "\n",
        "Train the Model:"
      ],
      "metadata": {
        "id": "CAzP--Z1t9X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "id": "ra6j3nJGt9eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is trained using the training data. It's trained for 5 epochs with a batch size of 64 and validated using the test data.\n",
        "\n",
        "Evaluate the Model:"
      ],
      "metadata": {
        "id": "G9n84t22t9np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "id": "SnOo5vqrt9uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained model's performance is evaluated on the test dataset, and the test accuracy is printed."
      ],
      "metadata": {
        "id": "Rqpt4OsrvDp5"
      }
    }
  ]
}